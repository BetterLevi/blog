<!DOCTYPE html>
<html lang="zh-cmn-Hans">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <meta http-equiv="X-UA-Compatible" content="ie=edge">
  <title>Why So Serious?</title>
  
    <link rel="icon" href="/blog/assets/smile.JPG">
  
  
  
  <!--link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/9.10.0/styles/github-gist.min.css"-->
  
<link rel="stylesheet" href="//cdn.jsdelivr.net/highlight.js/9.10.0/styles/github-gist.min.css">

  
<link rel="stylesheet" href="/blog/css/style.css">

<meta name="generator" content="Hexo 5.3.0"></head>

<body>
<div class="Shell">
    <aside class='SideBar'>
    <section class='avatar' style="background-image: url(/blog/assets/header.png)">
        <div class='av-pic' style="background-image: url(/blog/assets/avatar.jpg)">
        </div>
    </section>
    <section class='menu'>
        <div>Why So Serious?</div>
        
        <ul>
          
            <a href="/blog/" class="Btn">
              <li>Home</li>
            </a>  
          
            <a href="/blog/categories/" class="Btn">
              <li>Categories</li>
            </a>  
          
            <a href="/blog/about/" class="Btn">
              <li>About</li>
            </a>  
          
        </ul>
    </section>
    <section class="media">
        
    </section>
</aside>

    <div class="container">
        <div data-pager-shell>
            <ul class="Index">
  
    <header class='PageTitle'>
        <h1>{ Spark }</h1>
    </header>
  
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/blog/2021/09/08/Spark%E9%87%8D%E6%96%B0%E5%88%86%E5%8C%BARepartition/">Spark重新分区Repartition</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2021-09-08T03:11:46.000Z" itemprop="datePublished">
    2021-09-08
  </time>
  
  
  / 
  <ul>
    
  <li class="meta-text">
  { <a href="/blog/categories/BigData/">BigData</a> }
  </li>

  <li class="meta-text">
  { <a href="/blog/categories/BigData/Spark/">Spark</a> }
  </li>

  <li class="meta-text">
  { <a href="/blog/categories/BigData/Spark/%E8%AF%91/">译</a> }
  </li>


  </ul>
  
</div>

    </header>
    <div>
      
        <a id="more"></a>

<p>在分布式环境中，数据合理分布是提高性能的关键因素。在SparkSQL的DataFrame API中有一个*repartition()*函数用于控制数据在Spark集群上分布。然而高效地使用这个函数并不容易因为改变数据分布就意味着集群节点间物理数据移动（即Shuffle）的损耗。</p>
<p>根据经验来看，使用repartition消耗较大因为该操作会导致shuffle。这篇文章中我们将更加深入的探讨在某些情景下，在合适的位置增加一个shuffle并移除其他两个shuffle会使整体执行更加高效。我们先来了解一些概念来理解关于数据分布的信息在Spark SQL中是如何内部利用的，然后再介绍一些使用repartition的实际示例。</p>
<p>本篇文章中提到的概念基于Spark源代码，版本为snapshot3.1，大多数概念也适用于先前的版本2.x。并且这些理论和内部行为对语言是透明的，跟我们用Scala，Java或者是Python API使用无关。</p>
<h3 id="查询计划Query-Plan"><a href="#查询计划Query-Plan" class="headerlink" title="查询计划Query Plan"></a>查询计划Query Plan</h3><p>Spark SQL的DataFrame API允许用户实现高级transfomations，这些transformations是惰性的，这意味着它们不会立即执行而是在引擎上被转换成一个查询计划。当用户调用一个需要输出结果的action时，查询计划才会被具体化，比如我们正在把transformation的结果保存到一些存储系统中。查询计划本身可以被分为两种类型：一个逻辑计划和一个物理计划。查询计划执行的过程取决于逻辑计划与物理计划。</p>
<h3 id="逻辑计划Logical-Plan"><a href="#逻辑计划Logical-Plan" class="headerlink" title="逻辑计划Logical Plan"></a>逻辑计划Logical Plan</h3><p>逻辑计划这个词代表着一个逻辑计划执行的多个步骤，逻辑计划本身就是一个查询的抽象表示，它是一个树形结构，树中的每个节点表示一个相关的操作。逻辑计划本身不会包括任何有关执行的具体信息或者用来计算转换Transformation的算法如聚合aggregation。它仅用一种方便优化的方式来表示查询的信息。</p>
<p>在逻辑计划期间，查询计划会被Spark优化器进行优化，优化器会运用一系列用来转化计划的规则，这些规则大多数基于启发式，举个例子来说，在执行其他操作之前先对数据进行过滤是更好的（会减少内存占用）等等。</p>
<h3 id="物理计划Physical-Plan"><a href="#物理计划Physical-Plan" class="headerlink" title="物理计划Physical Plan"></a>物理计划Physical Plan</h3><p>一旦逻辑计划被优化完成，物理计划就开始了。物理计划的作用是把逻辑计划转变为可以执行的物理执行计划。不想逻辑计划那样抽象，物理计划会表示很多有关执行的具体细节信息，因为它包括了执行期间需要用到的具体算法。</p>
<p>物理计划也由两步组成因为物理计划有两个版本：spark plan和executed plan。Spark plan也称作策略，逻辑计划中的每个节点会在spark plan中转换成一个或者多个操作。一个策略的例子是JoinSelection，spark会决定使用哪种算法来join数据。spark plan可以通过api来查看，如Scala中：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scala">df.queryExecution.sparkPlan<br></code></pre></td></tr></table></figure>
<p>在spark plan创建之后，还有一组其他的规则需要应用以创建最终的物理计划的版本，即executed plan。Executed plan将会执行生成RDD代码，查看executed plan我们可以简单地在DataFrame上调用explain，因为它实际上就是物理计划的最终版本。另外我们也可以去Spark UI上查看图形表示。</p>
<h3 id="EnsureRequirement（ER规则）"><a href="#EnsureRequirement（ER规则）" class="headerlink" title="EnsureRequirement（ER规则）"></a>EnsureRequirement（ER规则）</h3><p>将Spark plan转换成Executed plan的这组规则称作EnsureRequirement，这组规则需要确保数据被正确的分配，因为有些转换需要保证数据被正确分配如joins和aggregation。物理计划中的每个操作符都有两个重要的属性：outputPartitioning和outputOrdering，这两个属性携带着数据分布的信息，以及在给定时刻数据如何被分区和排序的。除了这些，每个操作还有两个其他属性：requiredChildDistribution和requiredChildOrdering，节点通过这两个属性对其子节点的outputPartitioning和outputOrdering值提出要求。某些操作不会有任何需求但是有些操作需要，比如SortMergeJoin，这个操作对于其子节点有很强的要求，它要求数据必须以joining key进行分区和排序，这样才能正确的merge。让我们来考虑一个join两个表的简单查询（这两个表都是基于文件的数据源，格式为parquet）：</p>
<figure class="highlight scala"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scala">spark.table(<span class="hljs-string">&quot;tableA&quot;</span>).join(spark.table(<span class="hljs-string">&quot;tableB&quot;</span>), <span class="hljs-string">&quot;id&quot;</span>).write...<br></code></pre></td></tr></table></figure>
<p>这个查询的spark plan看起来像下面这样：</p>
<p><img src="/blog/images/sparkplan1.png" alt="Spark Plan"></p>
<p>从spark plan中可以看到SortMergeJoin的子节点（两个Project操作）没有outputPartitioning和outputOrdering并且这是数据还没有提前重新分区和表未被分桶的常见情况。当ER规则应用于这个spark plan时会发现SortMergeJoin的需求没有满足，所有它将在这个计划上进行全部交换Exchange和排序Sort来满足需求。交换操作负责对数据重新分区以满足requiredChildDistribution需求，排序操作负责对数据进行排序来满足requiredChildOrdering，所以最终的执行计划看上去像下图所示（这个也可以在Spark UI上查看，但是不会看到spark plan因为到这一步时它已经不存在了）</p>
<p><img src="/blog/images/sparkplan2.png" alt="final Spark Plan"></p>
<h3 id="分桶"><a href="#分桶" class="headerlink" title="分桶"></a>分桶</h3><p>如果两个表都根据joining key分桶了那么情况将有所不同。分桶是一种将数据存储在预shuffle和可能的预排序状态的技术，其中bucket的信息存储在megastore中。在上述例子中，如果每个桶中有一个确定的文件，FileScan操作会根据metastore中的信息获取outputPartitioning设置，outputOrdering也会被设置并且会被传递给下游Project。如果两个表根据joining key被分桶到相同数量的桶中，那么有关outputOrdering的需求就会被满足，ER规则将不会在spark plan上执行交换操作。join两侧的相同分区数在这里至关重要，如果这些数据不同，exchange操作会在每个与默认分区数不同的分支上执行一遍，默认<em>spark.sql.shuffle.partitions=200</em>。所以合适正确的分桶可以让join操作进行shuffle。</p>
<p>需要理解的重要一点是，Spark需要了解分布才能使用它，所以即使你的数据使用分桶进行了预shuffle，除非你将数据作为表来读取以从megastore中获取信息，否则spark不会知道这些信息所以不会在FileScan上设置outputPartitioning。</p>
<h3 id="Repartition"><a href="#Repartition" class="headerlink" title="Repartition"></a>Repartition</h3><p>正如文章开始提到的，repartition函数可以用来改变数据在spark集群上的分配。这个函数将数据应该被分布的列作为参数列（可选项是第一个参数可以指定要被分区的数量）。引擎上发生的事情是，它将一个RepartitionByExpression节点添加到逻辑计划中，然后使用策略将其转换为Spark plan中的exchange，并将outputPartitioning设置为HashPartitioning，hash键是用作参数的列名。</p>
<p>repartition函数另一种使用是仅指定一个参数，就是要被重新分区的数量，这种方式数据将会随机分布。</p>
<p><a target="_blank" rel="noopener" href="https://towardsdatascience.com/should-i-repartition-836f7842298c">原文实际示例</a></p>

      
    </div>
</article>

    </li>
  
    <li>
      <article class='ListView'>
    <header class="title">
      
        <h1>
          <a href="/blog/2021/09/06/Spark%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86/">Spark相关知识</a>
        </h1>
      
      <div class='ListMeta'>
  <time datetime="2021-09-06T10:41:08.000Z" itemprop="datePublished">
    2021-09-06
  </time>
  
  
  / 
  <ul>
    
  <li class="meta-text">
  { <a href="/blog/categories/BigData/">BigData</a> }
  </li>

  <li class="meta-text">
  { <a href="/blog/categories/BigData/Spark/">Spark</a> }
  </li>


  </ul>
  
</div>

    </header>
    <div>
      
        <a id="more"></a>

<h3 id="Spark特点"><a href="#Spark特点" class="headerlink" title="Spark特点"></a>Spark特点</h3><ol>
<li>快：与Hadoop的MapReduce相比，Spark基于内存的运算要快100倍以上，基于硬盘的运算也要快10倍以上，Spark实现了高效的DAG执行引擎，可以基于内存来高效处理数据流</li>
<li>易用：Spark支持Java，Python，R，Scala的API，还支持超过80种高级算法，使用户可以快速构建不同的应用。也支持交互式的python和scala的shell，可以很方便的在shell中使用spark来验证解决问题的方法</li>
<li>通用：spark提供了统一的解决方案。Spark可以用于批处理，交互式查询Spark SQL，实时流处理Spark Streaming，机器学习MLlib和图计算GraphX。</li>
<li>兼容性：Spark可以很方便的与其他开源产品进行融合。Spark可以使用Hadoop 的YARN和Apache     Mesos作为它的资源管理和调度器，并且可以处理所有Hadoop支持的数据，包括HDFS，HBase和Cassandra等。Spark也可以不依赖于第三方的资源管理和调度器，它实现了Standalone作为其内置的资源管理和调度框架，降低了Spark的使用门槛。</li>
</ol>
<h3 id="RDD知识点"><a href="#RDD知识点" class="headerlink" title="RDD知识点"></a>RDD知识点</h3><ol>
<li>RDD不实际存储真正要计算的数据，而是记录了数据的位置在哪里，数据的转换关系（调用了什么方法，传入了什么函数）</li>
<li>RDD中的所有转换都是惰性求值/延迟执行的，也就是说不会直接计算，只有当发生一个要求返回结果给Driver的Action时，这些转换才会真正运行。</li>
<li>使用惰性求值的原因是可以在Action时对RDD操作形成DAG有向无环图进行Stage的划分和并行优化，这种设计让Spark更加有效率地执行</li>
<li>RDD的算子分为两类：Transformation（返回一个新的RDD，map，filter等）和Action操作（返回值不是RDD或无返回值，reduce，collect等）。</li>
<li>实际开发中如果某一个RDD后续会被频繁的使用，可以将该RDD进行持久化/缓存</li>
</ol>
<h3 id="数据分类"><a href="#数据分类" class="headerlink" title="数据分类"></a>数据分类</h3><ol>
<li>结构化数据：有固定的schema，如关系型数据库中的表</li>
<li>半结构化数据：没有固定的schema，但是有结构，数据一般是自描述性的，如Json</li>
<li>非结构化数据：没有固定的schema，也没有结构，如图片或音频之类的</li>
<li>RDD可以处理上述三种数据，SparkSQL主要用于处理结构化数据</li>
</ol>
<h3 id="Shuffle知识点"><a href="#Shuffle知识点" class="headerlink" title="Shuffle知识点"></a>Shuffle知识点</h3><ol>
<li><p>要实现Tungsten-Sort Shuffle机制需要满足一下条件：</p>
<ul>
<li>Shuffle依赖中不带聚合操作或者没有对输出进行排序的要求</li>
<li>Shuffle的序列化器支持序列化值的重定位（当前仅支持Kryo Serializer Spark     SQL框架自定义的序列化器）</li>
<li>  Shuffle过程中输出的分区个数少于16777216个</li>
</ul>
</li>
<li><p>Spark Shuffle分为两种：基于Hash的Shuffle和基于Sort的Shuffle，</p>
<ul>
<li><p>Hash Shuffle特点：</p>
<ul>
<li>优点是可以省略不必要的排序开销，避免了排序所需的内存开销；</li>
<li>缺点<ul>
<li>生产的文件过多，会对文件系统造成压力</li>
<li>大量小文件的随机读写带来一定的磁盘开销</li>
<li>数据块写入时所需的缓存空间也会随之增加，对内存造成压力。</li>
</ul>
</li>
</ul>
</li>
<li><p>Sort Shuffle特点：</p>
<ul>
<li><p>优点：</p>
<ul>
<li>小文件的数量大大减少，mapper端的内存占用变少</li>
<li>Spark不仅可以处理小规模的数据，即使处理大规模的数据也不会很容易的达到性能瓶颈</li>
</ul>
</li>
<li><p>缺点：</p>
<ul>
<li>如果mapper中task的数量过大，依旧会产生很多小文件，此时在shuffle传数据的过程中到reduce端，reduce会需要同时大量的记录进行反序列化，导致大量内存消耗和GC负担巨大，造成系统缓慢甚至奔溃</li>
<li>强制了mapper端必须要排序，即使数据本身并不需要排序</li>
<li>要基于记录本身进行排序，性能消耗很大</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<h3 id="Spark运行流程"><a href="#Spark运行流程" class="headerlink" title="Spark运行流程"></a>Spark运行流程</h3><ol>
<li>SparkContext向资源管理器注册并向资源管理器申请运行Executor</li>
<li>资源管理器分配Executor然后资源管理器启动executor</li>
<li>Executor发送心跳到资源管理器</li>
<li>SparkContext构建DAG执行图</li>
<li>将DAG分解成Stage（TaskSet）</li>
<li>把Stage发送给TaskScheduler</li>
<li>Executor向SparkContext申请Task</li>
<li>TaskScheduler将task发送给Executor运行</li>
<li>同时SparkContext将应用程序代码发放给Executor</li>
<li>task在Executor上运行，运行完毕释放所有资源</li>
</ol>
<h3 id="Spark数据倾斜"><a href="#Spark数据倾斜" class="headerlink" title="Spark数据倾斜"></a>Spark数据倾斜</h3><ol>
<li>Spark中的数据倾斜问题主要是指shuffle过程中出现的数据倾斜问题，是由于不同的key对应的数据量不同导致的不同task所处理的数据量不同的问题</li>
<li>解决方案：<ul>
<li>预聚合原始数据：避免shuffle过程；增大key粒度</li>
<li>预处理导致倾斜的key：过滤；使用随机key；sample采样对倾斜key单独进行join</li>
<li>提高并行度： reduce端并行度的设置，该方法并没有从根本上改变数据倾斜的本质问题，只是尽可能去缓解和减轻shuffle reduce task的数据压力，以及数据倾斜的问题，适用于有校对key对应的数据量都比较大的情况</li>
<li>使用map join：将较小RDD中的数据直接通过collect算子拉取到Driver端的内存中，然后对其创建一个broadcast变量；接着对另一个RDD执行map类算子，在算子函数内，从broadcast变量中获取较小RDD的全量数据，与当前RDD的每一条数据按照连接key进行比对，如果连接key相同的话，那么就将两个RDD的数据用需要的方式连接起来。这种思路不会发生shuffle操作，从根本上杜绝了join操作可能导致的数据倾斜问题，但是适用条件有限，比较适合有join操作产生数据倾斜问题且其中一个RDD的数据量较小。</li>
</ul>
</li>
</ol>
<h3 id="Spark性能优化"><a href="#Spark性能优化" class="headerlink" title="Spark性能优化"></a>Spark性能优化</h3><ol>
<li>RDD复用<br>使用缓存，缓存将DataFrame，数据表或者RDD放入集群中执行器的临时存储区（内存或磁盘），这将使后续读取更快。但是缓存数据会导致序列化，反序列化和存储开销。因此缓存适用于多次重复使用相同数据集的情形。</li>
<li>尽早filter，减少对内存的占用</li>
<li>读取大量小文件，使用wholeTextFiles</li>
<li>合理使用mapPartition和foreachPartition</li>
<li>并行度设置，即各个stage的task数量。官方推荐，task数量应该设置为spark作业总CPU core数量的2-3倍</li>
<li>使用持久化和checkpoint</li>
<li>使用广播变量</li>
</ol>
<h3 id="Spark相关问题"><a href="#Spark相关问题" class="headerlink" title="Spark相关问题"></a>Spark相关问题</h3><h4 id="Spark运行效率比MapReduce效率高在哪里"><a href="#Spark运行效率比MapReduce效率高在哪里" class="headerlink" title="Spark运行效率比MapReduce效率高在哪里"></a>Spark运行效率比MapReduce效率高在哪里</h4><p>spark是借鉴了Mapreduce,并在其基础上发展起来的，继承了其分布式计算的优点并进行了改进，spark生态更为丰富，功能更为强大，性能更加适用范围广，mapreduce更简单，稳定性好。主要区别：</p>
<ul>
<li>spark把运算的中间数据(shuffle阶段产生的数据)存放在内存，迭代计算效率更高，mapreduce的中间结果需要落地，保存到磁盘</li>
<li> Spark容错性高，它通过弹性分布式数据集RDD来实现高效容错，RDD是一组分布式的存储在节点内存中的只读性的数据集，这些集合石弹性的，某一部分丢失或者出错，可以通过整个数据集的计算流程的血缘关系来实现重建，mapreduce的容错只能重新计算</li>
<li>Spark更通用，提供了transformation和action这两大类的多功能api，另外还有流式处理sparkstreaming模块、图计算等等，mapreduce只提供了map和reduce两种操作，流计算及其他的模块支持比较缺乏</li>
<li>Spark框架和生态更为复杂，有RDD，血缘lineage、执行时的有向无环图DAG，stage划分等，很多时候spark作业都需要根据不同业务场景的需要进行调优以达到性能要求，mapreduce框架及其生态相对较为简单，对性能的要求也相对较弱，运行较为稳定，适合长期后台运行</li>
<li>Spark计算框架对内存的利用和运行的并行度比mapreduce高，Spark运行容器为executor，内部ThreadPool中线程运行一个Task，mapreduce在线程内部运行container，container容器分类为MapTask和ReduceTask。Spark程序运行并行度高</li>
<li>Spark对于executor的优化，在JVM虚拟机的基础上对内存弹性利用：storage memory与Execution memory的弹性扩容，使得内存利用效率更高</li>
</ul>
<h4 id="Hadoop和Spark的相同点和不同点"><a href="#Hadoop和Spark的相同点和不同点" class="headerlink" title="Hadoop和Spark的相同点和不同点"></a>Hadoop和Spark的相同点和不同点</h4><p>Hadoop底层使用MapReduce计算架构，只有map和reduce两种操作，表达能力比较欠缺，而且在MR过程中会重复的读写hdfs，造成大量的磁盘io读写操作，所以适合高时延环境下批处理计算的应用；</p>
<p>Spark是基于内存的分布式计算架构，提供更加丰富的数据集操作类型，主要分成转化操作和行动操作，包括map、reduce、filter、flatmap、groupbykey、reducebykey、union和join等，数据分析更加快速，所以适合低时延环境下计算的应用；</p>
<p>spark与hadoop最大的区别在于迭代式计算模型。基于mapreduce框架的Hadoop主要分为map和reduce两个阶段，两个阶段完了就结束了，所以在一个job里面能做的处理很有限；spark计算模型是基于内存的迭代式计算模型，可以分为n个阶段，根据用户编写的RDD算子和程序，在处理完一个阶段后可以继续往下处理很多个阶段，而不只是两个阶段。所以spark相较于mapreduce，计算模型更加灵活，可以提供更强大的功能。</p>
<p>但是spark也有劣势，由于spark基于内存进行计算，虽然开发容易，但是真正面对大数据的时候，在没有进行调优的情况下，可能会出现各种各样的问题，比如OOM内存溢出等情况，导致spark程序可能无法运行起来，而mapreduce虽然运行缓慢，但是至少可以慢慢运行完</p>
<h4 id="RDD持久化原理"><a href="#RDD持久化原理" class="headerlink" title="RDD持久化原理"></a>RDD持久化原理</h4><p>spark非常重要的一个功能特性就是可以将RDD持久化在内存中。</p>
<p>调用cache()和persist()方法即可。cache()和persist()的区别在于，cache()是persist()的一种简化方式，cache()的底层就是调用persist()的无参版本persist(MEMORY_ONLY)，将数据持久化到内存中。</p>
<p>如果需要从内存中清除缓存，可以使用unpersist()方法。RDD持久化是可以手动选择不同的策略的。在调用persist()时传入对应的StorageLevel即可。</p>
<h4 id="Checkpoint机制"><a href="#Checkpoint机制" class="headerlink" title="Checkpoint机制"></a>Checkpoint机制</h4><p>应用场景：当spark应用程序特别复杂，从初始的RDD开始到最后整个应用程序完成有很多的步骤，而且整个应用运行时间特别长，这种情况下就比较适合使用checkpoint功能。</p>
<p>原因：对于特别复杂的Spark应用，会出现某个反复使用的RDD，即使之前持久化过但由于节点的故障导致数据丢失了，没有容错机制，所以需要重新计算一次数据。</p>
<p>Checkpoint首先会调用SparkContext的setCheckPointDIR()方法，设置一个容错的文件系统的目录，比如说HDFS；然后对RDD调用checkpoint()方法。之后在RDD所处的job运行结束之后，会启动一个单独的job，来将checkpoint过的RDD数据写入之前设置的文件系统，进行高可用、容错的类持久化操作。</p>
<p>检查点机制是我们在spark  streaming中用来保障容错性的主要机制，它可以使spark streaming阶段性的把应用数据存储到诸如HDFS等可靠存储系统中，以供恢复时使用。具体来说基于以下两个目的服务：</p>
<ul>
<li><p>控制发生失败时需要重算的状态数。Spark streaming可以通过转化图的谱系图来重算状态，检查点机制则可以控制需要在转化图中回溯多远。</p>
</li>
<li><p>提供驱动器程序容错。如果流计算应用中的驱动器程序崩溃了，你可以重启驱动器程序并让驱动器程序从检查点恢复，这样spark streaming就可以读取之前运行的程序处理数据的进度，并从那里继续。</p>
</li>
</ul>
<h4 id="checkpoint和持久化的区别"><a href="#checkpoint和持久化的区别" class="headerlink" title="checkpoint和持久化的区别"></a>checkpoint和持久化的区别</h4><p>最主要的区别在于持久化只是将数据保存在BlockManager中，但是RDD的lineage(血缘关系，依赖关系)是不变的。但是checkpoint执行完之后，rdd已经没有之前所谓的依赖rdd了，而只有一个强行为其设置的checkpointRDD，checkpoint之后rdd的lineage就改变了。</p>
<p>持久化的数据丢失的可能性更大，因为节点的故障会导致磁盘、内存的数据丢失。但是checkpoint的数据通常是保存在高可用的文件系统中，比如HDFS中，所以数据丢失可能性比较低</p>
<h4 id="RDD机制"><a href="#RDD机制" class="headerlink" title="RDD机制"></a>RDD机制</h4><p>rdd分布式弹性数据集，简单的理解成一种数据结构，是spark框架上的通用货币。所有算子都是基于rdd来执行的，不同的场景会有不同的rdd实现类，但是都可以进行互相转换。rdd执行过程中会形成dag图，然后形成lineage保证容错性等。从物理的角度来看rdd存储的是block和node之间的映射。</p>
<p>RDD是spark提供的核心抽象，全称为弹性分布式数据集。</p>
<p>RDD在逻辑上是一个hdfs文件，在抽象上是一种元素集合，包含了数据。它是被分区的，分为多个分区，每个分区分布在集群中的不同结点上，从而让RDD中的数据可以被并行操作（分布式数据集）</p>
<p>比如有个RDD有90W数据，3个partition，则每个分区上有30W数据。RDD通常通过Hadoop上的文件，即HDFS或者HIVE表来创建，还可以通过应用程序中的集合来创建；RDD最重要的特性就是容错性，可以自动从节点失败中恢复过来。即如果某个结点上的RDD partition因为节点故障，导致数据丢失，那么RDD可以通过自己的数据来源重新计算该partition。这一切对使用者都是透明的。</p>
<p>RDD的数据默认存放在内存中，但是当内存资源不足时，spark会自动将RDD数据写入磁盘。比如某结点内存只能处理20W数据，那么这20W数据就会放入内存中计算，剩下10W放到磁盘中。RDD的弹性体现在于RDD上自动进行内存和磁盘之间权衡和切换的机制。</p>

      
    </div>
</article>

    </li>
  
</ul>


            <footer>
    <div>© 2021 - Levi </div>
    <div>
        <span>
<!--            Powered by <a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a>-->
            Homo sum, humani nihil a me alienum puto
        </span>
    </div>
<!--    {% if theme.footer.counter %}-->
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span id="busuanzi_container_site_pv">Views <span id="busuanzi_value_site_pv"></span> </span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">Visitors <span id="busuanzi_value_site_uv"></span> </span>
<!--    {% endif %}-->
</footer>

        </div>
    </div>
</div>

<script src="/blog/js/pager/dist/singlepager.js"></script>

<script>
var sp = new Pager('data-pager-shell')

</script>
</body>
</html>